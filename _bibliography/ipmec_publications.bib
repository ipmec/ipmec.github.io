@article{aviles22,
  title = {High Complexity Reliable Space Applications in Commercial Microprocessors},
  author = {Aviles, Pablo M. and Sch{\"a}fer, Laura and Lindoso, Almudena and Belloch, Jose A. and Entrena, Luis},
  year = {2022},
  month = sep,
  journal = {Microelectronics Reliability},
  pages = {114679},
  issn = {0026-2714},
  doi = {10.1016/j.microrel.2022.114679},
  urldate = {2022-10-11},
  abstract = {Reliability requirements are critical in applications used in harsh environments. Although commercial microprocessors offer a good trade-off between cost, size, and performance, they must be tailored to meet tight reliability requirements. This work focuses on the reliability of a real space data intensive application. As a case study we have selected an ESA space benchmark that processes images of a near infrared detector (NIR-Hawaii) involving a large quantity of data with a high computational load. The reliability of the system has been accomplished with the improvement of a macro-synchronized lockstep hardening technique, taking into account the specific special needs of data intensive applications. The microprocessor implementation platform is a commercial dual-core ARM cortex A9 microprocessor. Extensive fault injection campaigns have been carried out in both memory and register file to evaluate the proposed approach. Experimental results demonstrate the high reliability of the proposed hardened system, with error detection capabilities of 100~\% and improved system recovery capabilities.},
  langid = {english},
  keywords = {COTS,Fault tolerance,Hardening,Lockstep,Microprocessor,Reliability},
  file = {C\:\\Users\\rial9\\Zotero\\storage\\524XLC5V\\Aviles et al. - 2022 - High complexity reliable space applications in com.pdf;C\:\\Users\\rial9\\Zotero\\storage\\5LTV762U\\S0026271422002037.html}
}

@article{badia_access20,
  ids = {badia2020gpu},
  title = {{{GPU Acceleration}} of a {{Non-Standard Finite Element Mesh Truncation Technique}} for {{Electromagnetics}}},
  author = {Bad{\'i}a, Jos{\'e} M. and {Amor-Martin}, Adrian and Belloch, Jose A. and {Garc{\'i}a-Castillo}, Luis E.},
  date = {2020},
  year = {2020},
  journal = {IEEE Access},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {94719--94730},
  publisher = {IEEE},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2993103},
  abstract = {The emergence of General Purpose Graphics Processing Units (GPGPUs) provides new opportunities to accelerate applications involving a large number of regular computations. However, properly leveraging the computational resources of graphical processors is a very challenging task. In this paper, we use this kind of device to parallelize FE-IIEE (Finite Element-Iterative Integral Equation Evaluation), a non-standard finite element mesh truncation technique introduced by two of the authors. This application is computationally very demanding due to the amount, size and complexity of the data involved in the procedure. Besides, an efficient implementation becomes even more difficult if the parallelization has to maintain the complex workflow of the original code. The proposed implementation using CUDA applies different optimization techniques to improve performance. These include leveraging the fastest memories of the GPU and increasing the granularity of the computations to reduce the impact of memory access. We have applied our parallel algorithm to two real radiation and scattering problems demonstrating speedups higher than 140 on a state-of-the-art GPU.},
  copyright = {All rights reserved},
  html = {https://doi.org/10.1109/ACCESS.2020.2993103},
  jcr = {3.367 (2020)},
  jcrcat = {Q2, 94/273 (Engineering, Electrical and Electronic)},
  selected = {false},
  keywords = {CUDA,electromagnetics,finite elements,GPU},
  file = {C\:\\Users\\rial9\\Zotero\\storage\\SISX25AF\\Bad√≠a et al. - 2020 - GPU Acceleration of a Non-Standard Finite Element .pdf;C\:\\Users\\rial9\\Zotero\\storage\\G3GSFDFR\\9088972.html}
}

@article{badia_js22,
  title = {Strategies to Parallelize a Finite Element Mesh Truncation Technique on Multi-Core and Many-Core Architectures},
  author = {Badia, Jose M. and {Amor-Martin}, Adrian and Belloch, Jose A. and {Garcia-Castillo}, Luis Emilio},
  date = {2022},
  year = {2023},
  journal = {The Journal of Supercomputing},
  journaltitle = {The Journal of Supercomputing},
  volume = {79},
  pages = {7648--7664},
  publisher = {Springer US},
  issn = {1573-0484},
  doi = {10.1007/s11227-022-04975-6},
  urldate = {2022-12-04},
  abstract = {Achieving maximum parallel performance on multi-core CPUs and many-core GPUs is a challenging task depending on multiple factors. These include, for example, the number and granularity of the computations or the use of the memories of the devices. In this paper, we assess those factors by evaluating and comparing different parallelizations of the same problem on a multiprocessor containing a CPU with 40 cores and four P100 GPUs with Pascal architecture. We use, as study case, the convolutional operation behind a non-standard finite element mesh truncation technique in the context of open region electromagnetic wave propagation problems. A total of six parallel algorithms implemented using OpenMP and CUDA have been used to carry out the comparison by leveraging the same levels of parallelism on both types of platforms. Three of the algorithms are presented for the first time in this paper, including a multi-GPU method, and two others are improved versions of algorithms previously developed by some of the authors. This paper presents a thorough experimental evaluation of the parallel algorithms on a radar cross-sectional prediction problem. Results show that performance obtained on the GPU clearly overcomes those obtained in the CPU, much more so if we use multiple GPUs to distribute both data and computations. Accelerations close to 30 have been obtained on the CPU, while with the multi-GPU version accelerations larger than 250 have been achieved.},
  html = {https://doi.org/10.1007/s11227-022-04975-6},
  jcr = {2.5},
  jcrcat = {Q2, 48/144 (Computer Science, Theory \& Methods)},
  langid = {english},
  selected = {false},
  keywords = {CUDA,Finite elements,GPU,OpenMP,Parallel computing},
  file = {C:\Users\rial9\Zotero\storage\NGVY38JU\Badia et al. - 2022 - Strategies to parallelize a finite element mesh tr.pdf}
}

@article{badia24b,
  title = {Analysing the Radiation Reliability, Performance and Energy Consumption of Low-Power {{SoC}} through Heterogeneous Parallelism},
  author = {Badia, Jose M. and Leon, German and {Garcia-Valderas}, Mario and Belloch, Jose A. and Lindoso, Almudena and Entrena, Luis},
  year = {2024},
  month = dec,
  journal = {Sustainable Computing: Informatics and Systems},
  volume = {44},
  pages = {101049},
  issn = {2210-5379},
  doi = {10.1016/j.suscom.2024.101049},
  urldate = {2025-11-18},
  abstract = {This study focuses on the low-power Tegra X1 System-on-Chip (SoC) from the Jetson Nano Developer Kit, which is increasingly used in various environments and tasks. As these SoCs grow in prevalence, it becomes crucial to analyse their computational performance, energy consumption, and reliability, especially for safety-critical applications. A key factor examined in this paper is the SoC's neutron radiation tolerance. This is explored by subjecting a parallel version of matrix multiplication, which has been offloaded to various hardware components via OpenMP, to neutron irradiation. Through this approach, this researcher establishes a correlation between the SoC's reliability and its computational and energy performance. The analysis enables the identification of an optimal workload distribution strategy, considering factors such as execution time, energy efficiency, and system reliability. Experimental results reveal that, while the GPU executes matrix multiplication tasks more rapidly and efficiently than the CPU, using both components only marginally reduces execution time. Interestingly, GPU usage significantly increases the SoC's critical section, leading to an escalated error rate for both Detected Unrecoverable Errors (DUE) and Silent Data Corruptions (SDC), with the CPU showing a higher average number of affected elements per SDC.},
  keywords = {Energy consumption,Fault tolerance,Heterogeneous parallelism,Neutron irradiation,System-on-Chip},
  file = {C:\Users\rial9\Zotero\storage\DC5QPAEL\S2210537924000945.html}
}

@article{badia25,
  title = {Reliability of {{Vision Transformers}} and {{CNNs}} on {{Edge AI Systems Under Neutron Radiation}}},
  author = {Badia, Jose M. and {Martin-Salinas}, Ignacio and Leon, German and {Amor-Martin}, Adrian and {Frias-Dominguez}, Lester and Belloch, Jose A. and {Garcia-Valderas}, Mario and Lindoso, Almudena and Cazzaniga, Carlo and Entrena, Luis},
  year = {2025},
  month = aug,
  journal = {IEEE Transactions on Nuclear Science},
  volume = {72},
  number = {8},
  pages = {2706--2716},
  issn = {1558-1578},
  doi = {10.1109/TNS.2025.3536519},
  selected = {true},
  urldate = {2025-11-18},
  abstract = {The reliability of neural networks on Edge AI platforms is crucial for safety-critical applications, especially in environments exposed to radiation. This article presents an experimental evaluation of the reliability of Vision Transformers (ViTs) and convolutional neural networks (CNNs) deployed on low-power system-on-chip (SoC) devices, specifically the Jetson Orin Nano. The study explores the impact of neutron radiation on these models, focusing on the effect of optimization techniques such as tensor runtime (TensorRT), data precision reduction, and weight quantization. Results indicate that while optimization can improve inference performance, it may also increase the error rates in outputs. Additionally, including main memory in the radiation tests resulted in severe persistent errors, highlighting the need for thorough reliability assessments in real-world scenarios. A comparison between ViTs and CNNs revealed that ViTs, despite their complexity, show comparable or better reliability on modern SoCs, which is critical for deploying AI in safety-critical environments like aerospace and autonomous driving.},
  keywords = {Convolutional neural network (CNN),Convolutional neural networks,Edge AI,Edge AI platform,Graphics processing units,Libraries,neutron radiation,Neutrons,Optimization,Performance evaluation,Quantization (signal),radiation reliability,Reliability,Transformers,Vision Transformer (ViT)},
  file = {C:\Users\rial9\Zotero\storage\ML5ARDED\badia_25_reliabilityofvisio.pdf}
}

@article{belloch19,
  title = {On the {{Use}} of {{Many-Core Machines}} for the {{Acceleration}} of a {{Mesh Truncation Technique}} for {{FEM}}},
  author = {Belloch, Jose A. and {Amor-Martin}, Adrian and {Garcia-Donoro}, Daniel and {Mart{\'i}nez-Zald{\'i}var}, Francisco J. and {Garcia-Castillo}, Luis E.},
  year = {2019},
  journal = {The Journal of Supercomputing},
  volume = {75},
  pages = {1686--1696},
  doi = {10.1007/S11227-018-02739-9},
  abstract = {Finite element method (FEM) has been used for years for radiation problems in the field of electromagnetism. To tackle problems of this kind, mesh truncation techniques are required, which may lead to the use of high computational resources. In fact, electrically large radiation problems can only be tackled using massively parallel computational resources. Different types of multi-core machines are commonly employed in diverse fields of science for accelerating a number of applications. However, properly managing their computational resources becomes a very challenging task. On the one hand, we present a hybrid message passing interface + OpenMP-based acceleration of a mesh truncation technique included in a FEM code for electromagnetism in a high-performance computing cluster equipped with 140 compute nodes. Results show that we obtain about 85\% of the theoretical maximum speedup of the machine. On the other hand, a graphics processing unit has been used to accelerate one of the parts that presents high fine-grain parallelism.},
  copyright = {All rights reserved}
}

@article{belloch24,
  title = {Urban Sound Classification Using Neural Networks on Embedded {{FPGAs}}},
  author = {Belloch, Jose A. and Coronado, Raul and Valls, Oscar and {del Amor}, Roc{\'i}o and Leon, German and Naranjo, Valery and Dolz, Manuel F. and {Amor-Martin}, Adrian and Pi{\~n}ero, Gema},
  year = {2024},
  month = jun,
  journal = {The Journal of Supercomputing},
  volume = {80},
  number = {9},
  pages = {13176--13186},
  issn = {1573-0484},
  doi = {10.1007/s11227-024-05947-8},
  urldate = {2025-11-18},
  abstract = {Sound classification using neural networks has recently produced very accurate results. A large number of different applications use this type of sound classifiers such as controlling and monitoring the type of activity in a city or identifying different types of animals in natural environments. While traditional acoustic processing applications have been developed on high-performance computing platforms equipped with expensive multi-channel audio interfaces, the Internet of Things (IoT) paradigm requires the use of more flexible and energy-efficient systems. Although software-based platforms exist for implementing general-purpose neural networks, they are not optimized for sound classification, wasting energy and computational resources. In this work, we have used FPGAs to develop an ad hoc system where only the hardware needed for our application is synthesized, resulting in faster and more energy-efficient circuits. The results show that our developments are accelerated by a factor of 35 compared to a software-based implementation on a Raspberry Pi.},
  langid = {english},
  keywords = {Convolutional neural networks,Deep learning,FPGA,Hardware acceleration,Sound classification},
  file = {C:\Users\rial9\Zotero\storage\FRB5Y2IH\belloch_24_urbansoundclassifi.pdf}
}

@article{belloch24a,
  title = {Efficient Velvet-Noise Convolution in Multicore Processors},
  author = {Belloch, Jose A. and Badia, Jose M. and Leon, German and V{\"a}lim{\"a}ki, Vesa},
  year = {2024},
  journal = {AES: Journal of the Audio Engineering Society},
  volume = {72},
  number = {6},
  pages = {383--393},
  selected = {true},
  publisher = {Audio Engineering Society},
  urldate = {2025-11-18}
}

@article{frias-dominguez25,
  title = {Radiation {{Reliability}} of {{System Reboots}} in {{Commercial Off-the-Shelf SoC}}},
  author = {{Frias-Dominguez}, Lester and Leon, German and Badia, Jose M. and Belloch, Jose A. and {Garcia-Valderas}, Mario and Lindoso, Almudena and Entrena, Luis},
  year = {2025},
  month = aug,
  journal = {IEEE Transactions on Nuclear Science},
  volume = {72},
  number = {8},
  pages = {2662--2670},
  issn = {1558-1578},
  doi = {10.1109/TNS.2025.3539942},
  urldate = {2025-11-18},
  abstract = {This study investigates the reliability of system reboots in modern low-power system-on-chip (SoC) devices when exposed to terrestrial neutron radiation. The focus is on understanding how single-event functional interrupts (SEFIs) caused by neutron strikes affect system downtime during reboot processes. Three commercial off-the-shelf (COTS) SoCs from NVIDIA, namely, the Jetson Nano with Tegra X1 SoC and two models of Jetson Orin Nano with 4- and 8-GB memory, were subjected to high-flux neutron radiation. The research assesses the number and duration of reboots caused by SEFIs and their consequent impact on overall system downtime. Results reveal that the reboot process has a significantly higher cross section compared to application-level operations such as matrix multiplication and neural network inference, which highlights its vulnerability to radiation. The study further categorizes the reboots based on their triggers and identifies common system messages linked to radiation-induced errors. It also shows that different phases of the boot flow have different radiation reliabilities. The findings underscore the importance of evaluating boot processes in radiation-intensive environments, especially for safety-critical applications where minimizing downtime is crucial.},
  keywords = {Graphics processing units,Linux,Neural networks,Neutron,Neutrons,Power system management,Process control,radiation,Radiation effects,Reliability,Software,Space missions,system downtime,system reboot,system-on-chip (SoC)},
  file = {C:\Users\rial9\Zotero\storage\CNB629IH\frias-dominguez_25_radiationreliabilit.pdf}
}

@article{leon24,
  title = {Comparative Analysis of Soft-Error Sensitivity in {{LU}} Decomposition Algorithms on Diverse {{GPUs}}},
  author = {Leon, German and Badia, Jose M. and Belloch, Jose A. and Lindoso, Almudena and Entrena, Luis},
  year = {2024},
  month = jun,
  journal = {The Journal of Supercomputing},
  volume = {80},
  number = {9},
  pages = {12844--12862},
  issn = {1573-0484},
  doi = {10.1007/s11227-024-05925-0},
  urldate = {2025-11-18},
  abstract = {Graphics processing units (GPUs) have become integral to embedded systems and supercomputing centres due to their large memory, cutting-edge technology and high performance per watt. However, their susceptibility to transient errors requires a comprehensive analysis of error sensitivity, as well as the development of error mitigation techniques and fault-tolerant algorithms. This study focuses on evaluating the soft-error sensitivity of two distinct versions of LU decomposition algorithms implemented on two very different GPUs---a low-power SoC embedded GPU and a high-performance massively parallel GPU. Through extensive fault injection campaigns on both GPUs, we examine the vulnerability of the algorithms, identify error causes, and determine critical code components requiring enhanced protection. The experiments reveal that most single bit flip fault injections in the instruction results lead to erroneous outcomes or unrecoverable errors. Notably, efficient GPU resource utilisation can increase the number of masked errors, thereby enhancing error resilience. Additionally, while different parts of the code exhibit similar error occurrence types and rates, the propagation of errors to elements within the result matrix differs significantly.},
  langid = {english},
  keywords = {Fault injection,GPU,LU decomposition,Sensitivity,Soft errors},
  file = {C:\Users\rial9\Zotero\storage\YE2RJ3ZG\leon_24_comparativeanalysis.pdf}
}

@article{leon24a,
  title = {Analyzing the {{Influence}} of {{Memory}} and {{Workload}} on the {{Reliability}} of {{GPUs Under Neutron Radiation}}},
  author = {Leon, German and Badia, Jose M. and Belloch, Jose A. and {Garcia-Valderas}, Mario and Lindoso, Almudena and Entrena, Luis},
  year = {2024},
  month = aug,
  journal = {IEEE Transactions on Nuclear Science},
  volume = {71},
  number = {8},
  pages = {1487--1495},
  issn = {1558-1578},
  doi = {10.1109/TNS.2024.3387490},
  urldate = {2025-11-18},
  abstract = {Evaluating the impact of utilizing different GPU resources is crucial for gaining insights into the reliability of GPUs when exposed to radiation. In this study, we employed various versions of a microbenchmark to investigate the effect of different memory types on the performance of a low-power GPU integrated into the Tegra X1 (TX1) system on a chip (SoC) of a Jetson Nano board. Additionally, we explored the tradeoff between enhanced computational performance and the occurrence of failures over time by optimizing the utilization of GPU resources. Our findings demonstrate that maximizing the utilization of the device's cores enables the completion of a greater number of computations without errors. By fully harnessing the computational potential of the GPU cores, we effectively increase the work that we can complete between failures. Moreover, we observed that the use of the different memory types has a significant influence on the overall reliability of the GPU. The outcomes of this research contribute to a comprehensive understanding of the interplay between GPU resources, irradiation effects, and reliability. This knowledge is instrumental in guiding the development of robust GPUs for applications in radiation-prone environments.},
  keywords = {Benchmark testing,Fault tolerance,GPU,Graphics processing units,Instruction sets,Memory,Microarchitecture,microbenchmark,neutron,Neutron radiation effects,radiation,Radiation effects,Registers,Reliability,soft error,System-on-chip},
  file = {C:\Users\rial9\Zotero\storage\25SP2IWY\leon_24_analyzingtheinflue.pdf}
}

@article{lloria24,
  title = {Optimizing {{Millimeter Wave MIMO Channel Estimation Through GPU-Based Edge Artificial Intelligence}}},
  author = {Lloria, Diego and Roger, Sandra and Le{\'o}n, Germ{\'a}n and Bad{\'i}a, Jos{\'e} M. and {Botella-Mascarell}, Carmen and Belloch, Jose A.},
  year = {2024},
  month = dec,
  journal = {The Journal of Supercomputing},
  volume = {81},
  number = {1},
  pages = {270},
  issn = {1573-0484},
  doi = {10.1007/s11227-024-06795-2},
  urldate = {2025-11-18},
  abstract = {In the context of upcoming sixth-generation (6G) wireless communication systems, the use of millimeter wave (mmWave) frequencies is a key technology for achieving high-throughput communications. Accurate parametric estimation of mmWave channels is critical for effective beamforming design and configuration, requiring sophisticated models to capture the directional characteristics of these channels. This work considers an innovative artificial intelligence (AI) approach for accurate estimation of angle-of-arrival (AoA) and angle-of-departure (AoD) parameters from frequency-domain channel observations. Our approach is based on the implementation of two convolutional neural networks (CNNs): a residual CNN (ResNet) and a U-Net CNN. Specifically, this work focuses on the efficient implementation of both schemes in an embedded system suitable for edge AI. We performed the experiments in a low-power NVIDIA Jetson Orin Nano platform and evaluated the effect of modifying the frequencies of its CPU and GPU on the performance of the inference process, both in terms of execution time and energy consumption. Experimental results showed that the U-Net model is more power consuming, but as it is faster, it consumes less energy per channel.},
  langid = {english},
  keywords = {Artificial intelligence,Channel estimation,Edge computing,Graphic processing units,MIMO communication systems},
  file = {C:\Users\rial9\Zotero\storage\DTCVT3QU\lloria_24_optimizingmillimete.pdf}
}

@article{martin-salinas24,
  title = {Evaluating and Accelerating Vision Transformers on {{GPU-based}} Embedded Edge {{AI}} Systems},
  author = {{Martin-Salinas}, Ignacio and Badia, Jose M. and Valls, Oscar and Leon, German and {del Amor}, Rocio and Belloch, Jose A. and {Amor-Martin}, Adrian and Naranjo, Valery},
  year = {2024},
  month = dec,
  journal = {The Journal of Supercomputing},
  volume = {81},
  number = {1},
  pages = {349},
  issn = {1573-0484},
  doi = {10.1007/s11227-024-06807-1},
  urldate = {2025-11-18},
  abstract = {Many current embedded systems comprise heterogeneous computing components including quite powerful GPUs, which enables their application across diverse sectors. This study demonstrates the efficient execution of a medium-sized self-supervised audio spectrogram transformer (SSAST) model on a low-power system-on-chip (SoC). Through comprehensive evaluation, including real time inference scenarios, we show that GPUs outperform multi-core CPUs in inference processes. Optimization techniques such as adjusting batch size, model compilation with TensorRT, and reducing data precision significantly enhance inference time, energy consumption, and memory usage. In particular, negligible accuracy degradation is observed, with post-training quantization to 8-bit integers showing less than 1\% loss. This research underscores the feasibility of deploying transformer neural networks on low-power embedded devices, ensuring efficiency in time, energy, and memory, while maintaining the accuracy of the results.},
  langid = {english},
  selected = {true},
  keywords = {GPU,Low-power system-on-chip,Vision transformer},
  file = {C:\Users\rial9\Zotero\storage\HWVLY7AP\martin-salinas_24_evaluatingandaccel.pdf}
}

@article{martin-salinas25,
  title = {Enhanced {{U-Net}} Architectures for Accurate Room Impulse Response Generation via Differential-Phase Learning},
  author = {{Martin-Salinas}, Ignacio and Pi{\~n}ero, Gema and Belloch, Jose A. and {Amor-Martin}, Adrian},
  year = {2025},
  month = nov,
  journal = {EURASIP Journal on Audio, Speech, and Music Processing},
  volume = {2025},
  number = {1},
  pages = {39},
  issn = {1687-4722},
  doi = {10.1186/s13636-025-00430-5},
  urldate = {2025-11-17},
  abstract = {Generating accurate room impulse responses (RIRs) remains challenging, particularly regarding phase estimation. Building upon previous work utilizing encoder-decoder deep learning architectures, this paper investigates advanced techniques to improve phase prediction accuracy. We propose and evaluate several enhanced U-Net models, including variants with a variational autoencoder (VAE) bottleneck and differing input conditioning methods for spatial and room parameters (embedding layers vs. normalized dense layers). A key focus is the comparison between predicting direct phase and differential phase. Furthermore, we analyze the impact of using mean absolute error (MAE) versus mean squared error (MSE) for the magnitude component of the loss function. The study also explores the efficacy of applying the Griffin-Lim algorithm as a post-processing step to refine the phase estimated by the networks. Performance is evaluated on a real RIR dataset, comparing the different model architectures, information vector encoding strategies, phase targets (direct vs. differential), loss functions, and the contribution of phase recovery algorithms to overall RIR fidelity. Results provide insights into effective strategies for enhancing phase generation in data-driven RIR synthesis.},
  keywords = {Deep learning,Gen AI,RIR,Signal processing},
  file = {C\:\\Users\\rial9\\Zotero\\storage\\IA9UNPP9\\martin-salinas_25_enhancedunetarchi.pdf;C\:\\Users\\rial9\\Zotero\\storage\\4H4DTGD6\\s13636-025-00430-5.html}
}

@article{martin-salinas25a,
  ids = {martin_js25},
  title = {Evaluating and Accelerating Vision Transformers on {{GPU-based}} Embedded Edge {{AI}} Systems},
  author = {{Martin-Salinas}, Ignacio and Badia, Jose M. and Valls, Oscar and Leon, German and {del Amor}, Rocio and Belloch, Jose A. and {Amor-Martin}, Adrian and Naranjo, Valery},
  date = {2024},
  year = {2025},
  journal = {The Journal of Supercomputing},
  journaltitle = {The Journal of Supercomputing},
  volume = {81},
  number = {1},
  pages = {349},
  publisher = {Springer US},
  issn = {1573-0484},
  doi = {10.1007/s11227-024-06807-1},
  urldate = {2025-02-08},
  abstract = {Many current embedded systems comprise heterogeneous computing components including quite powerful GPUs, which enables their application across diverse sectors. This study demonstrates the efficient execution of a medium-sized self-supervised audio spectrogram transformer (SSAST) model on a low-power system-on-chip (SoC). Through comprehensive evaluation, including real time inference scenarios, we show that GPUs outperform multi-core CPUs in inference processes. Optimization techniques such as adjusting batch size, model compilation with TensorRT, and reducing data precision significantly enhance inference time, energy consumption, and memory usage. In particular, negligible accuracy degradation is observed, with post-training quantization to 8-bit integers showing less than 1\% loss. This research underscores the feasibility of deploying transformer neural networks on low-power embedded devices, ensuring efficiency in time, energy, and memory, while maintaining the accuracy of the results.},
  html = {https://doi.org/10.1007/s11227-022-04975-6},
  jcr = {2.5 (2023)},
  jcrcat = {Q2, 47/143 (Computer Science, Theory \& Methods)},
  langid = {english},
  selected = {false},
  keywords = {Artificial Intelligence,GPU,Low-power system-on-chip,Vision transformer},
  file = {G:\My Drive\Obsidian\Obsidian Vault\zotero_pdf\My papers (to export)\Indexed papers\martin-salinas24a.pdf}
}
